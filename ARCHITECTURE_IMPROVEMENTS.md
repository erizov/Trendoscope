# üèóÔ∏è Architecture Improvements for Robustness & Extensibility

## Executive Summary

This document outlines architectural improvements to make Trendoscope more robust, maintainable, and extensible. The focus is on design patterns, abstraction layers, and architectural principles that enable easier testing, scaling, and feature additions.

---

## üéØ Current Architecture Assessment

### Strengths
- ‚úÖ Service layer pattern implemented
- ‚úÖ Separation of concerns (API, Services, Data)
- ‚úÖ Type hints and validation
- ‚úÖ Structured logging
- ‚úÖ Rate limiting

### Weaknesses
- ‚ùå Direct instantiation in API endpoints
- ‚ùå Hard-coded dependencies
- ‚ùå No dependency injection container
- ‚ùå Limited abstraction layers
- ‚ùå No plugin system
- ‚ùå Configuration scattered
- ‚ùå No event system
- ‚ùå Limited error recovery strategies

---

## üöÄ Proposed Improvements

### 1. Dependency Injection Container ‚≠ê‚≠ê‚≠ê

**Problem**: Services are instantiated directly, making testing and swapping implementations difficult.

**Solution**: Implement a DI container using `dependency-injector` or custom solution.

**Benefits**:
- Easy mocking for tests
- Centralized dependency management
- Configuration-driven component selection
- Lifecycle management

**Implementation**:
```python
# src/trendascope/core/container.py
from dependency_injector import containers, providers

class ApplicationContainer(containers.DeclarativeContainer):
    """Dependency injection container."""
    
    # Configuration
    config = providers.Configuration()
    
    # Database
    news_db = providers.Singleton(
        NewsDatabase,
        db_path=config.database.news_path
    )
    
    # Services
    news_service = providers.Factory(
        NewsService,
        aggregator=providers.Singleton(NewsAggregator),
        scorer=providers.Singleton(ControversyScorer),
        db=news_db
    )
    
    post_service = providers.Factory(
        PostService,
        generator=providers.Singleton(PostGenerator),
        db=news_db
    )
```

**Usage**:
```python
# In API endpoints
from ..core.container import container

@app.get("/api/news/feed")
async def get_news_feed(
    news_service: NewsService = Depends(lambda: container.news_service())
):
    return news_service.fetch_news_feed()
```

---

### 2. Repository Pattern ‚≠ê‚≠ê‚≠ê

**Problem**: Data access logic is mixed with business logic, making it hard to swap storage backends.

**Solution**: Abstract data access behind repository interfaces.

**Benefits**:
- Easy to swap SQLite ‚Üí PostgreSQL ‚Üí MongoDB
- Testable with in-memory implementations
- Clear separation of data access

**Implementation**:
```python
# src/trendascope/core/repositories.py
from abc import ABC, abstractmethod
from typing import List, Dict, Optional

class NewsRepository(ABC):
    """Abstract news repository."""
    
    @abstractmethod
    def save(self, item: Dict[str, Any]) -> Optional[int]:
        """Save news item."""
        pass
    
    @abstractmethod
    def find_by_language(self, language: str, limit: int) -> List[Dict[str, Any]]:
        """Find news by language."""
        pass
    
    @abstractmethod
    def search(self, query: str, limit: int) -> List[Dict[str, Any]]:
        """Search news."""
        pass

# Concrete implementation
class SQLiteNewsRepository(NewsRepository):
    """SQLite implementation."""
    def __init__(self, db_path: str):
        self.db = NewsDatabase(db_path)
    
    def save(self, item: Dict[str, Any]) -> Optional[int]:
        return self.db.add_news(**item)
    
    # ... implement other methods

# In-memory for testing
class InMemoryNewsRepository(NewsRepository):
    """In-memory implementation for testing."""
    def __init__(self):
        self._items = []
    
    def save(self, item: Dict[str, Any]) -> Optional[int]:
        item['id'] = len(self._items) + 1
        self._items.append(item)
        return item['id']
```

---

### 3. Plugin System ‚≠ê‚≠ê‚≠ê

**Problem**: Adding new LLM providers, news sources, or features requires modifying core code.

**Solution**: Plugin architecture with discovery and registration.

**Benefits**:
- Add features without modifying core
- Third-party extensions
- Hot-swappable components
- Version compatibility

**Implementation**:
```python
# src/trendascope/core/plugins.py
from abc import ABC, abstractmethod
from typing import Dict, Any, List
import importlib
import pkgutil

class LLMProviderPlugin(ABC):
    """Base class for LLM provider plugins."""
    
    @property
    @abstractmethod
    def name(self) -> str:
        """Plugin name."""
        pass
    
    @abstractmethod
    def call(self, prompt: str, **kwargs) -> str:
        """Call LLM."""
        pass
    
    @abstractmethod
    def check_balance(self) -> bool:
        """Check if provider has balance."""
        pass

class PluginRegistry:
    """Plugin registry and discovery."""
    
    def __init__(self):
        self._providers: Dict[str, LLMProviderPlugin] = {}
        self._news_sources: Dict[str, NewsSourcePlugin] = {}
    
    def register_provider(self, provider: LLMProviderPlugin):
        """Register LLM provider."""
        self._providers[provider.name] = provider
    
    def get_provider(self, name: str) -> Optional[LLMProviderPlugin]:
        """Get provider by name."""
        return self._providers.get(name)
    
    def discover_plugins(self, package: str):
        """Auto-discover plugins in package."""
        # Scan package for plugin classes
        pass

# Example plugin
class CustomLLMPlugin(LLMProviderPlugin):
    name = "custom_llm"
    
    def call(self, prompt: str, **kwargs) -> str:
        # Custom implementation
        pass
```

---

### 4. Event-Driven Architecture ‚≠ê‚≠ê

**Problem**: Components are tightly coupled, making it hard to add cross-cutting concerns.

**Solution**: Event bus for decoupled communication.

**Benefits**:
- Loose coupling
- Easy to add listeners (logging, metrics, notifications)
- Async processing
- Audit trail

**Implementation**:
```python
# src/trendascope/core/events.py
from typing import Callable, Dict, Any, List
from dataclasses import dataclass
from datetime import datetime
import asyncio

@dataclass
class Event:
    """Base event class."""
    name: str
    timestamp: datetime
    data: Dict[str, Any]

class EventBus:
    """Event bus for decoupled communication."""
    
    def __init__(self):
        self._listeners: Dict[str, List[Callable]] = {}
    
    def subscribe(self, event_name: str, handler: Callable):
        """Subscribe to event."""
        if event_name not in self._listeners:
            self._listeners[event_name] = []
        self._listeners[event_name].append(handler)
    
    async def publish(self, event: Event):
        """Publish event to all subscribers."""
        handlers = self._listeners.get(event.name, [])
        await asyncio.gather(*[handler(event) for handler in handlers])

# Usage
event_bus = EventBus()

# Subscribe
event_bus.subscribe("news.fetched", log_news_fetch)
event_bus.subscribe("news.fetched", update_metrics)
event_bus.subscribe("post.generated", track_costs)

# Publish
await event_bus.publish(Event(
    name="news.fetched",
    timestamp=datetime.now(),
    data={"count": 10, "sources": ["rss1", "rss2"]}
))
```

---

### 5. Configuration Management ‚≠ê‚≠ê‚≠ê

**Problem**: Configuration is scattered across files and environment variables.

**Solution**: Centralized configuration with validation and defaults.

**Benefits**:
- Single source of truth
- Type-safe configuration
- Environment-specific configs
- Validation on startup

**Implementation**:
```python
# src/trendascope/core/config.py
from pydantic_settings import BaseSettings
from pydantic import Field, validator
from typing import Optional, List

class DatabaseConfig(BaseSettings):
    """Database configuration."""
    news_db_path: str = Field(default="data/news.db")
    post_db_path: str = Field(default="data/posts.json")
    connection_pool_size: int = Field(default=10)
    
    class Config:
        env_prefix = "DB_"

class LLMConfig(BaseSettings):
    """LLM configuration."""
    openai_api_key: Optional[str] = None
    anthropic_api_key: Optional[str] = None
    default_provider: str = Field(default="free")
    max_tokens: int = Field(default=2000)
    temperature: float = Field(default=0.8)
    
    class Config:
        env_prefix = "LLM_"

class AppConfig(BaseSettings):
    """Application configuration."""
    database: DatabaseConfig = Field(default_factory=DatabaseConfig)
    llm: LLMConfig = Field(default_factory=LLMConfig)
    log_level: str = Field(default="INFO")
    debug: bool = Field(default=False)
    
    @validator('log_level')
    def validate_log_level(cls, v):
        assert v in ['DEBUG', 'INFO', 'WARNING', 'ERROR']
        return v
    
    class Config:
        env_file = ".env"
        env_file_encoding = "utf-8"

# Global config
config = AppConfig()
```

---

### 6. Abstract Factory Pattern ‚≠ê‚≠ê

**Problem**: Creating related objects (providers, repositories) requires knowing implementation details.

**Solution**: Abstract factories for object creation.

**Benefits**:
- Consistent object creation
- Easy to swap implementations
- Configuration-driven

**Implementation**:
```python
# src/trendascope/core/factories.py
from abc import ABC, abstractmethod

class StorageFactory(ABC):
    """Abstract factory for storage components."""
    
    @abstractmethod
    def create_news_repository(self) -> NewsRepository:
        pass
    
    @abstractmethod
    def create_post_repository(self) -> PostRepository:
        pass

class SQLiteStorageFactory(StorageFactory):
    """SQLite factory."""
    def __init__(self, config: DatabaseConfig):
        self.config = config
    
    def create_news_repository(self) -> NewsRepository:
        return SQLiteNewsRepository(self.config.news_db_path)
    
    def create_post_repository(self) -> PostRepository:
        return SQLitePostRepository(self.config.post_db_path)

class PostgreSQLStorageFactory(StorageFactory):
    """PostgreSQL factory."""
    # Similar implementation for PostgreSQL
    pass
```

---

### 7. Circuit Breaker Pattern ‚≠ê‚≠ê

**Problem**: External services (LLM APIs, RSS feeds) can fail and cause cascading failures.

**Solution**: Circuit breaker to prevent repeated calls to failing services.

**Benefits**:
- Prevents cascading failures
- Automatic recovery
- Graceful degradation

**Implementation**:
```python
# src/trendascope/core/circuit_breaker.py
from enum import Enum
from datetime import datetime, timedelta
from typing import Callable, Any
import time

class CircuitState(Enum):
    CLOSED = "closed"  # Normal operation
    OPEN = "open"      # Failing, reject requests
    HALF_OPEN = "half_open"  # Testing recovery

class CircuitBreaker:
    """Circuit breaker for external services."""
    
    def __init__(
        self,
        failure_threshold: int = 5,
        timeout: int = 60,
        expected_exception: type = Exception
    ):
        self.failure_threshold = failure_threshold
        self.timeout = timeout
        self.expected_exception = expected_exception
        self.failure_count = 0
        self.last_failure_time = None
        self.state = CircuitState.CLOSED
    
    def call(self, func: Callable, *args, **kwargs) -> Any:
        """Call function with circuit breaker protection."""
        if self.state == CircuitState.OPEN:
            if self._should_attempt_reset():
                self.state = CircuitState.HALF_OPEN
            else:
                raise Exception("Circuit breaker is OPEN")
        
        try:
            result = func(*args, **kwargs)
            self._on_success()
            return result
        except self.expected_exception as e:
            self._on_failure()
            raise
    
    def _on_success(self):
        """Handle successful call."""
        self.failure_count = 0
        self.state = CircuitState.CLOSED
    
    def _on_failure(self):
        """Handle failed call."""
        self.failure_count += 1
        self.last_failure_time = datetime.now()
        
        if self.failure_count >= self.failure_threshold:
            self.state = CircuitState.OPEN
    
    def _should_attempt_reset(self) -> bool:
        """Check if should attempt reset."""
        if not self.last_failure_time:
            return True
        return (datetime.now() - self.last_failure_time).seconds >= self.timeout

# Usage
breaker = CircuitBreaker(failure_threshold=5, timeout=60)

try:
    result = breaker.call(translator.translate, text)
except Exception:
    # Fallback to demo mode
    result = demo_translate(text)
```

---

### 8. Retry with Exponential Backoff ‚≠ê‚≠ê

**Problem**: Transient failures cause unnecessary errors.

**Solution**: Retry mechanism with exponential backoff.

**Benefits**:
- Handles transient failures
- Reduces load on failing services
- Improves reliability

**Implementation**:
```python
# src/trendascope/core/retry.py
import asyncio
from typing import Callable, Type, Tuple
from functools import wraps

def retry_with_backoff(
    max_attempts: int = 3,
    initial_delay: float = 1.0,
    max_delay: float = 60.0,
    exponential_base: float = 2.0,
    exceptions: Tuple[Type[Exception], ...] = (Exception,)
):
    """Retry decorator with exponential backoff."""
    def decorator(func: Callable):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            delay = initial_delay
            last_exception = None
            
            for attempt in range(max_attempts):
                try:
                    return await func(*args, **kwargs)
                except exceptions as e:
                    last_exception = e
                    if attempt < max_attempts - 1:
                        await asyncio.sleep(delay)
                        delay = min(delay * exponential_base, max_delay)
                    else:
                        raise
            
            raise last_exception
        return wrapper
    return decorator

# Usage
@retry_with_backoff(max_attempts=3, initial_delay=1.0)
async def fetch_news(url: str):
    # Fetch with automatic retry
    pass
```

---

### 9. Middleware Pipeline ‚≠ê‚≠ê

**Problem**: Cross-cutting concerns (logging, auth, validation) are mixed with business logic.

**Solution**: Middleware pipeline for request/response processing.

**Benefits**:
- Separation of concerns
- Reusable middleware
- Easy to add/remove features
- Testable components

**Implementation**:
```python
# src/trendascope/core/middleware.py
from typing import Callable, Awaitable
from fastapi import Request, Response

class Middleware:
    """Base middleware class."""
    
    async def process_request(self, request: Request) -> Optional[Response]:
        """Process request before handler."""
        return None
    
    async def process_response(self, request: Request, response: Response) -> Response:
        """Process response after handler."""
        return response

class MiddlewarePipeline:
    """Middleware pipeline."""
    
    def __init__(self):
        self._middlewares: List[Middleware] = []
    
    def add(self, middleware: Middleware):
        """Add middleware to pipeline."""
        self._middlewares.append(middleware)
    
    async def process(self, request: Request, handler: Callable) -> Response:
        """Process request through middleware pipeline."""
        # Process request
        for middleware in self._middlewares:
            response = await middleware.process_request(request)
            if response:
                return response
        
        # Call handler
        response = await handler(request)
        
        # Process response
        for middleware in reversed(self._middlewares):
            response = await middleware.process_response(request, response)
        
        return response
```

---

### 10. Health Check System ‚≠ê‚≠ê‚≠ê

**Problem**: No comprehensive health checking for all components.

**Solution**: Health check registry with component status.

**Benefits**:
- Monitor system health
- Detect issues early
- Graceful degradation
- Load balancer integration

**Implementation**:
```python
# src/trendascope/core/health.py
from typing import Dict, Any, Callable
from enum import Enum
from dataclasses import dataclass

class HealthStatus(Enum):
    HEALTHY = "healthy"
    DEGRADED = "degraded"
    UNHEALTHY = "unhealthy"

@dataclass
class HealthCheckResult:
    """Health check result."""
    status: HealthStatus
    message: str
    details: Dict[str, Any]

class HealthChecker:
    """Health check registry."""
    
    def __init__(self):
        self._checks: Dict[str, Callable] = {}
    
    def register(self, name: str, check: Callable):
        """Register health check."""
        self._checks[name] = check
    
    async def check_all(self) -> Dict[str, HealthCheckResult]:
        """Run all health checks."""
        results = {}
        for name, check in self._checks.items():
            try:
                result = await check()
                results[name] = result
            except Exception as e:
                results[name] = HealthCheckResult(
                    status=HealthStatus.UNHEALTHY,
                    message=str(e),
                    details={}
                )
        return results
    
    async def check_overall(self) -> HealthStatus:
        """Get overall health status."""
        results = await self.check_all()
        statuses = [r.status for r in results.values()]
        
        if HealthStatus.UNHEALTHY in statuses:
            return HealthStatus.UNHEALTHY
        elif HealthStatus.DEGRADED in statuses:
            return HealthStatus.DEGRADED
        else:
            return HealthStatus.HEALTHY

# Register checks
health_checker = HealthChecker()

health_checker.register("database", check_database)
health_checker.register("cache", check_cache)
health_checker.register("llm_openai", check_openai)
health_checker.register("llm_anthropic", check_anthropic)
```

---

### 11. Async/Await Throughout ‚≠ê‚≠ê‚≠ê

**Problem**: Mix of sync and async code causes blocking and poor performance.

**Solution**: Convert all I/O operations to async.

**Benefits**:
- Better performance
- Non-blocking operations
- Higher concurrency
- Scalability

**Implementation**:
```python
# Convert sync operations to async
import asyncio
from concurrent.futures import ThreadPoolExecutor

class AsyncNewsAggregator:
    """Async news aggregator."""
    
    def __init__(self):
        self.executor = ThreadPoolExecutor(max_workers=10)
    
    async def fetch_rss_feed(self, url: str) -> List[Dict]:
        """Fetch RSS feed asynchronously."""
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(
            self.executor,
            self._fetch_sync,
            url
        )
    
    def _fetch_sync(self, url: str) -> List[Dict]:
        """Synchronous fetch (runs in thread pool)."""
        # Existing sync code
        pass
```

---

### 12. Caching Strategy ‚≠ê‚≠ê

**Problem**: No unified caching strategy, leading to redundant API calls.

**Solution**: Multi-level caching with TTL and invalidation.

**Benefits**:
- Reduced API calls
- Faster responses
- Cost savings
- Better UX

**Implementation**:
```python
# src/trendascope/core/cache.py
from typing import Optional, Callable, Any
from datetime import datetime, timedelta
import hashlib
import json

class CacheManager:
    """Unified cache manager."""
    
    def __init__(self):
        self._layers = []  # L1: Memory, L2: Redis, L3: Database
    
    async def get(self, key: str) -> Optional[Any]:
        """Get from cache (checks all layers)."""
        for layer in self._layers:
            value = await layer.get(key)
            if value:
                # Promote to higher layers
                await self._promote(key, value, layer)
                return value
        return None
    
    async def set(self, key: str, value: Any, ttl: int = 3600):
        """Set in all cache layers."""
        for layer in self._layers:
            await layer.set(key, value, ttl)
    
    def cache_key(self, func: Callable, *args, **kwargs) -> str:
        """Generate cache key from function and arguments."""
        key_data = {
            'func': func.__name__,
            'args': args,
            'kwargs': kwargs
        }
        key_str = json.dumps(key_data, sort_keys=True)
        return hashlib.md5(key_str.encode()).hexdigest()
```

---

## üìã Implementation Priority

### Phase 1: Foundation (Week 1-2)
1. ‚úÖ Dependency Injection Container
2. ‚úÖ Configuration Management
3. ‚úÖ Repository Pattern
4. ‚úÖ Health Check System

### Phase 2: Resilience (Week 3-4)
5. ‚úÖ Circuit Breaker Pattern
6. ‚úÖ Retry with Backoff
7. ‚úÖ Async/Await Conversion
8. ‚úÖ Caching Strategy

### Phase 3: Extensibility (Week 5-6)
9. ‚úÖ Plugin System
10. ‚úÖ Event-Driven Architecture
11. ‚úÖ Abstract Factory Pattern
12. ‚úÖ Middleware Pipeline

---

## üéØ Benefits Summary

### Robustness
- **Error Recovery**: Circuit breakers, retries, graceful degradation
- **Monitoring**: Health checks, metrics, logging
- **Resilience**: Handles failures gracefully

### Extensibility
- **Plugins**: Add features without modifying core
- **Abstractions**: Easy to swap implementations
- **Events**: Decoupled communication
- **Factories**: Configuration-driven creation

### Maintainability
- **DI Container**: Centralized dependencies
- **Repository Pattern**: Clear data access
- **Configuration**: Single source of truth
- **Testing**: Easy to mock and test

### Performance
- **Async**: Non-blocking operations
- **Caching**: Reduced API calls
- **Parallel Processing**: Better concurrency

---

## üìö References

- **Dependency Injection**: `dependency-injector` library
- **Event Bus**: Custom or `pyee` library
- **Circuit Breaker**: `pybreaker` library
- **Retry**: `tenacity` library
- **Configuration**: `pydantic-settings`

---

**Next Steps**: Start with Phase 1 (Foundation) and gradually implement improvements.

**Last Updated**: 2025-01-XX  
**Version**: 2.2.0

